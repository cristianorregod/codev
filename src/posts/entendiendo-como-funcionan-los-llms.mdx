---
title: 'Entendiendo c√≥mo funcionan los LLMs ü§ñ'
date: '2025-08-11'
description: >-
    Descubre c√≥mo los modelos de lenguaje (LLMs) usan vectores y embeddings para comprender y generar texto. Aprende qu√© son, c√≥mo funcionan y por qu√© cada palabra en tu prompt importa.
toc: true
tags:
    - AI
cover: '/images/posts/comprendiendo-los-llms.webp'
author: '@cristianorregodev'
---

Los modelos de lenguaje de gran escala (LLMs, por sus siglas en ingl√©s) como ChatGPT han revolucionado la forma en que interactuamos con la inteligencia artificial. 
Su capacidad para comprender y generar texto de forma coherente est√° profundamente ligada a dos conceptos clave: vectores y embeddings.
Si comprendemos estos fundamentos, podremos formular mejores prompts, optimizar resultados y aprovechar al m√°ximo el potencial de estas herramientas.

## ¬øQu√© son los vectores y c√≥mo se relacionan con los LLMs?

Un vector es, en esencia, una lista ordenada de n√∫meros que describe la posici√≥n o caracter√≠sticas de algo en un espacio definido por dimensiones. En f√≠sica, solemos 
imaginarlos en coordenadas X y Y, y con una tercera dimensi√≥n obtenemos mayor precisi√≥n: X, Y, Z.

En el caso de los LLMs, los vectores no se limitan a 2 o 3 dimensiones:

> - Pueden tener cientos o miles de dimensiones.
- Cada dimensi√≥n representa una caracter√≠stica abstracta de la palabra, como su contexto, categor√≠a gramatical o matiz emocional.

<br/>
En vez de ubicar un punto en un plano o en un cubo, un LLM ubica las palabras en un espacio multidimensional donde las distancias y direcciones representan relaciones de significado.

## ¬øQu√© rol juegan los embeddings en la comprensi√≥n del lenguaje?

Un embedding es un vector de muchas dimensiones que describe el significado de una palabra o frase. 
No solo se fija en su definici√≥n literal, sino tambi√©n en:

> - Contextos en los que aparece.
- Emociones asociadas.
- Categor√≠as y relaciones con otras palabras.

<br/>
**Ejemplo intuitivo:**<br/>
Cuando evaluamos un restaurante, no nos quedamos con un √∫nico criterio. Consideramos:

> - Calidad de la comida
- Ambiente
- Servicio
- Frescura de los ingredientes
- M√∫sica


<br/>
De forma similar, un embedding eval√∫a una palabra en m√∫ltiples dimensiones, permitiendo que un modelo entienda su significado con m√°s precisi√≥n.

## C√≥mo los embeddings conectan palabras en distintos idiomas
Uno de los poderes de los embeddings es que mapean significados, no solo palabras.
Por ejemplo:

> - Aguacate (espa√±ol)
- Avocado (ingl√©s)

<br/>
Ambas comparten atributos: fruta, color verde, textura cremosa. El modelo puede reconocer que se refieren a la misma cosa incluso sin traducir la palabra expl√≠citamente. 
Esto se debe a que en el espacio vectorial ambas est√°n muy pr√≥ximas.

## Por qu√© cada palabra en un prompt es crucial
Cuando escribimos un prompt para un LLM, cada palabra seleccionada mueve la conversaci√≥n hacia una zona diferente del espacio vectorial.

> - Cambiar una palabra puede acercar o alejar el significado esperado.
- Esto modifica el conjunto de relaciones sem√°nticas que el modelo explorar√° para responder.

<br/>
En otras palabras: la precisi√≥n de tu prompt determina la precisi√≥n de la respuesta.

## Conclusiones
Entender c√≥mo los LLMs representan el lenguaje mediante vectores y embeddings nos da una ventaja clave como usuarios.
No se trata solo de ‚Äúescribir una pregunta‚Äù, sino de construir una ruta precisa en el espacio sem√°ntico del modelo para obtener el resultado que queremos.

## Infograf√≠a

<img
  src="https://res.cloudinary.com/dvjzp6scj/image/upload/v1755053211/posts/Programando_con_AI_b5pdey.svg"
  alt="Infografia de entendiendo los LLMs"
/>
<br />